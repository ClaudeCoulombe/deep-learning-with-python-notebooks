{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Companion Notebook - 7.4 Test Hyperas\n",
    "## updated for TensorFlow & Keras 2.x\n",
    "## Chap 7 « Advanced Deep-learning best practices »\n",
    "## « Deep Learning with Python » book by François Chollet\n",
    "\n",
    "This notebook contains the code samples found in Chapter 7 of «Deep Learning with Python». Note that the original text features far more content, in particular further explanations and figures. In this companion Notebook, you will find source code along with small corrections and some additions by Claude COULOMBE - PhD - Montréal.\n",
    "\n",
    "### Complete example of optimization using Hyperas\n",
    "\n",
    "The main inspiration is coming from: Hyperas: Keras + Hyperopt: A very simple wrapper for convenient hyperparameter optimization\n",
    "\n",
    "https://github.com/maxpumperla/hyperas\n",
    "\n",
    "> sudo pip3 install hyperas\n",
    "\n",
    "I've got some errors using Hyperopt with Python3 on MacOS X\n",
    "\n",
    "1) Replace the future package\n",
    "    > sudo rm -R /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/future*\n",
    "   \n",
    "    > sudo pip3 install future\n",
    "    \n",
    "2) Edit base.py in the package hyperopt in order to replace basestring by str\n",
    "    > sudo nano /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/hyperopt/base.py\n",
    "\n",
    "    comment line 29\n",
    "    #from past.builtins import basestring\n",
    "    change line 140\n",
    "    #elif isinstance(arg, (basestring, float, int, int, type(None))):\n",
    "    elif isinstance(arg, (str, float, int, int, type(None))):\n",
    "    \n",
    " 3) Edit base.py in order to replace line 714 \n",
    "    https://github.com/maxpumperla/hyperas/issues/125\n",
    "    \n",
    "    > sudo nano /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/hyperopt/base.py\n",
    "    #order = nx.topological_sort(G) by\n",
    "    order = list(nx.topological_sort(G))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.3.1\n",
      "TensorFlow version: 2.2.0\n",
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'conditional': hp.choice('conditional', ['three', 'four']),\n",
      "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \"\"\"\n",
      "  3: Data providing function:\n",
      "  4: \n",
      "  5: This function is separated from create_model() so that hyperopt\n",
      "  6: won't reload data for each evaluation run.\n",
      "  7: \"\"\"\n",
      "  8: (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "  9: x_train = x_train.reshape(60000, 784)\n",
      " 10: x_test = x_test.reshape(10000, 784)\n",
      " 11: x_train = x_train.astype('float32')\n",
      " 12: x_test = x_test.astype('float32')\n",
      " 13: x_train /= 255\n",
      " 14: x_test /= 255\n",
      " 15: nb_classes = 10\n",
      " 16: y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      " 17: y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      " 18: \n",
      " 19: \n",
      " 20: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \"\"\"\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     \"\"\"\n",
      "  13:     model = Sequential()\n",
      "  14:     model.add(Dense(512, input_shape=(784,)))\n",
      "  15:     model.add(Activation('relu'))\n",
      "  16:     model.add(Dropout(space['Dropout']))\n",
      "  17:     model.add(Dense(space['Dense']))\n",
      "  18:     model.add(Activation(space['Activation']))\n",
      "  19:     model.add(Dropout(space['Dropout_1']))\n",
      "  20: \n",
      "  21:     # If we choose 'four', add an additional fourth layer\n",
      "  22:     if conditional(space['conditional']) == 'four':\n",
      "  23:         model.add(Dense(100))\n",
      "  24: \n",
      "  25:         # We can also choose between complete sets of layers\n",
      "  26: \n",
      "  27:         model.add(space['add'])\n",
      "  28:         model.add(Activation('relu'))\n",
      "  29: \n",
      "  30:     model.add(Dense(10))\n",
      "  31:     model.add(Activation('softmax'))\n",
      "  32: \n",
      "  33:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
      "  34:                   optimizer=space['optimizer'])\n",
      "  35: \n",
      "  36:     model.fit(x_train, y_train,\n",
      "  37:               batch_size=space['batch_size'],\n",
      "  38:               epochs=1,\n",
      "  39:               verbose=2,\n",
      "  40:               validation_data=(x_test, y_test))\n",
      "  41:     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
      "  42:     print('Test accuracy:', acc)\n",
      "  43:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  44: \n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " - 12s - loss: 1.8089 - accuracy: 0.3594 - val_loss: 0.7577 - val_accuracy: 0.8159\n",
      "Test accuracy: 0.8159000277519226\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " - 10s - loss: 2.2231 - accuracy: 0.2846 - val_loss: 0.7302 - val_accuracy: 0.7931\n",
      "Test accuracy: 0.7930999994277954\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " - 11s - loss: 1.9472 - accuracy: 0.3076 - val_loss: 0.6924 - val_accuracy: 0.8762\n",
      "Test accuracy: 0.8762000203132629\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " - 7s - loss: 0.7093 - accuracy: 0.7748 - val_loss: 0.2044 - val_accuracy: 0.9374\n",
      "Test accuracy: 0.9373999834060669\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      " - 16s - loss: 0.2813 - accuracy: 0.9133 - val_loss: 0.1465 - val_accuracy: 0.9546\n",
      "Test accuracy: 0.9545999765396118\n",
      "Evalutation of best performing model:\n",
      "10000/10000 [==============================] - 1s 96us/step\n",
      "[0.14648921155184508, 0.9545999765396118]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Activation': 1, 'Dense': 2, 'Dropout': 0.03323327852409652, 'Dropout_1': 0.0886198698550964, 'add': 1, 'batch_size': 0, 'conditional': 1, 'optimizer': 0}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# sudo pip3 install --ignore-installed --upgrade tensorflow\n",
    "import keras\n",
    "print(\"Keras version:\",keras.__version__)\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\",tf.__version__)\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "\n",
    "def data():\n",
    "    \"\"\"\n",
    "    Data providing function:\n",
    "\n",
    "    This function is separated from create_model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    nb_classes = 10\n",
    "    y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    # If we choose 'four', add an additional fourth layer\n",
    "    if conditional({{choice(['three', 'four'])}}) == 'four':\n",
    "        model.add(Dense(100))\n",
    "\n",
    "        # We can also choose between complete sets of layers\n",
    "\n",
    "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size={{choice([64, 128])}},\n",
    "              epochs=1,\n",
    "              verbose=2,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    notebook_name='7.4-Test_Hyperas'\n",
    "    best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name=notebook_name)\n",
    "    X_train, Y_train, X_test, Y_test = data()\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(X_test, Y_test))\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
